{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52314ed0",
   "metadata": {},
   "source": [
    "# Assignment 2: Python for Text Processing\n",
    "\n",
    "**Submission deadline:** Friday, 31 Oct 2025, 11:55 PM  \n",
    "**Assessment marks:** 35 marks (35% of the total unit assessment)\n",
    "\n",
    "---\n",
    "\n",
    "### Late Submission Penalty\n",
    "\n",
    "Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted.\n",
    "\n",
    "> **Example:** If the assignment is worth 8 marks (of the entire unit) and your submission is late by 19 hours (or 23 hours 59 minutes 59 seconds), 0.4 marks (5% of 8 marks) will be deducted. If your submission is late by 24 hours (or 47 hours 59 minutes 59 seconds), 0.8 marks (10% of 8 marks) will be deducted, and so on.\n",
    "\n",
    "The submission time for all uploaded assessments is **11:55 PM**. A **1-hour grace period** is provided for technical concerns.  Apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration), if you think you should be granted an extended deadline or waive the late submission penalty. You should apply immediately when the situation occurs.\n",
    "\n",
    "---\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "All submitted work must be your own. For rules around AI tools, refer to **\"Using Generative AI Tools\" on iLearn**.\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Complete the five tasks below.\n",
    "\n",
    "* Write your code and comments inside this notebook.\n",
    "\n",
    "* Your notebook must include the running outputs of your final code.\n",
    "\n",
    "* **Submit this `.ipynb` file, containing your code and outputs, to iLearn.**\n",
    "\n",
    "---\n",
    "\n",
    "### Assessment\n",
    "\n",
    "-  Marks are based on the correctness of your code, outputs, and coding style.\n",
    "-  A total of **2.5 marks** (0.5 per task) are awarded globally across the assignment for both of the below: (1) runnable codes; (2) good coding style: clean, modular code, meaningful variable names, and good comments.\n",
    "-  If outputs are missing or incorrect, up to **25% of the marks for that task** can be deducted.\n",
    "-  See each task below for the detailed mark breakdown.\n",
    "\n",
    "---\n",
    "\n",
    "### AI Tools Usage Policy\n",
    "\n",
    "\n",
    "In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and what you cannot do, please visit these information pages provided by Macquarie University.\n",
    "\n",
    "- See: [Artificial Intelligence Tools and Academic Integrity in FSE](https://bit.ly/3uxgQP4)\n",
    "\n",
    "If you choose to use these tools, make the following explicit in your submitted file as comments starting with \"Use of AI generators in this assignment\" :\n",
    "\n",
    "- What part of your code is based on the output of such tools,\n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code or text, and\n",
    "- What modifications you made on the generated code or text?\n",
    "\n",
    "This will help us assess your work fairly. \n",
    "\n",
    "**If we observe that you have used an AI generator and you do not give the above information, you may face disciplinary action.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6c533",
   "metadata": {},
   "source": [
    "\n",
    "## Objectives of this assignment\n",
    "\n",
    "In this assignment, you will work on the Quora Question Pairs (QQP) datset detailed below. The first two tasks will help you get familiar with the data, and the remaining requires you to implement deep neural networks.\n",
    "\n",
    "\n",
    "**About the Quora Question Pairs (QQP) Dataset**\n",
    "\n",
    "Description: A large dataset of 400k+ question pairs from Quora, labeled whether they are duplicates (semantically the same) or not. It features informal, noisy text with class imbalance, hard positives (low lexical overlap) and hard negatives (high overlap, different meaning). QQP is practically relevant for deduplicating FAQs, search, and support systems. Working on QQP builds transferable skills, such as text preprocessing, model comparison, threshold tuning, error analysis, and deployment-minded reasoning about real applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4113f16",
   "metadata": {},
   "source": [
    "**Get familiar with the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b74181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/comp3420/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/comp3420/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "!pip -q install datasets    # Install the datasets package to access the dataset\n",
    "# add the packages you used, and specify the verion you installed\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa8a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: mps\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "cuda - Nvidia GPU\n",
    "mps - Apple M1 GPU\n",
    "cpu - CPU of the device\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(\"The device is:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26cf6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17543e6f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55f743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load QQP\n",
    "ds = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "# Use validation set as our test; optionally create a smaller train subset for speed\n",
    "train_ds = ds[\"train\"]\n",
    "eval_ds  = ds[\"validation\"]\n",
    "\n",
    "q1_tr = list(train_ds[\"question1\"])\n",
    "q2_tr = list(train_ds[\"question2\"])\n",
    "y_tr  = np.array(train_ds[\"label\"])\n",
    "\n",
    "q1_te = list(eval_ds[\"question1\"])\n",
    "q2_te = list(eval_ds[\"question2\"])\n",
    "y_te  = np.array(eval_ds[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05743951",
   "metadata": {},
   "source": [
    "### Task 1. What is the top-5 common NOUN in the question1 and question2, respectively? (5 marks)\n",
    "\n",
    "Write codes that returns the top-5 common NOUN in the questions. To find the part of speech, use NLTK's \"Universal\" tag set. You may need to use NLTK's `sent_tokenize` and `word_tokenize` to get words. The function returns a list that is descendingly sorted according to freqency, e.g. [(noun1, 22), (noun2, 10), ...].\n",
    "<!-- To produce the correct results, the function must do this.  -->\n",
    "Hint: The following steps will produce the correct results:\n",
    "\n",
    "- Concatenate all questions together.\n",
    "- Use the NLTK libraries to find the tokens and the stems.\n",
    "- Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "- Use NLTK's part of speech tagger, using the \"Universal\" tagset.\n",
    "- Use NLTK's `pos_tag_sents` instead of `pos_tag`.\n",
    "\n",
    "Marking Criteria: \n",
    "- 2.5 marks for the correct codes and results of each column, namely question1 and question2 columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efc8fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokens(data):\n",
    "    sep = ' '\n",
    "    joined_data = sep.join(data)\n",
    "    wt = [nltk.word_tokenize(s) for s in nltk.sent_tokenize(joined_data)]\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a2d0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "def get_stems(word_tokens):\n",
    "    return [\n",
    "        [stemmer.stem(token.lower()) for token in sentence]\n",
    "        for sentence in word_tokens\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed073470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagged_words(word_token):\n",
    "    tagged_words_list = nltk.pos_tag_sents(word_token, tagset='universal')\n",
    "    return tagged_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb05fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_nouns(tagged_words_list, n_top=5):\n",
    "    tagged_nouns = [\n",
    "        stemmer.stem(tagged_word[0].lower())\n",
    "        for tagged_words in tagged_words_list\n",
    "        for tagged_word in tagged_words\n",
    "        if tagged_word[1] == 'NOUN'\n",
    "    ]\n",
    "    noun_counter = Counter(tagged_nouns)\n",
    "    return noun_counter.most_common(n_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfddf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tr_word_token = get_word_tokens(q1_tr)\n",
    "q2_tr_word_token = get_word_tokens(q2_tr)\n",
    "\n",
    "q1_tr_stem_token = get_stems(q1_tr_word_token)\n",
    "q2_tr_stem_token = get_stems(q2_tr_word_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ef8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tr_tagged_words = get_tagged_words(q1_tr_word_token)\n",
    "q2_tr_tagged_words = get_tagged_words(q2_tr_word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0659501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most common nouns in question1: [('india', 12708), ('peopl', 11507), ('way', 10598), ('differ', 8623), ('quora', 7678)]\n",
      "Top 5 most common nouns in question2: [('india', 13491), ('peopl', 12281), ('way', 11900), ('quora', 7967), ('time', 7579)]\n"
     ]
    }
   ],
   "source": [
    "most_common_nouns_in_q1 = get_most_common_nouns(q1_tr_tagged_words)\n",
    "most_common_nouns_in_q2 = get_most_common_nouns(q2_tr_tagged_words)\n",
    "print('Top 5 most common nouns in question1:', most_common_nouns_in_q1)\n",
    "print('Top 5 most common nouns in question2:', most_common_nouns_in_q2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ac4b3",
   "metadata": {},
   "source": [
    "### Task 2. What are the top-5 common stem 2-grams and non-stem 2-grams for question1 and question2, respectively? (5 marks)\n",
    "\n",
    "Write codes that returns the top-5 most frequent 2-grams (bigrams) of stemmed and non-stemmed tokens along with their normalized frequency from the question1 and question2 columns of the QQP dataset. The output should be in descending order of frequency, **with frequencies normalized by the total number of bigrams (rounded to 4 decimal places)**, e.g., `[(('what', 'is'), 0.0105), (('what', 'are'), 0.0053), ...]`.\n",
    "\n",
    "<!-- To produce the correct results, the function must do this: -->\n",
    "\n",
    "Hint: The following steps will produce the correct results:\n",
    "\n",
    "- Concatenate all questions together.\n",
    "- Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "- Use the NLTK libraries to find the tokens and the stems.\n",
    "- Use NLTK's Porter stemmer to get the root words.\n",
    "- Round normalized frequency to 4 precision after the decimal point.\n",
    "- When computing bigrams, do not consider words that are in different sentences. For example, if we have this text: `Sentence 1. And sentence 2.` the bigrams are: `('Sentence','1'), ('1','.'), ('.','And'), ('And','sentence')`, etc. Note that the following would not be a valid bigram, since the punctuation mark and the word \"And\" are in different sentences: `('.','And')`.\n",
    "\n",
    "Marking Criteria: \n",
    "- 2.5 marks for the correct codes and restuls of each column, namely question1 and question2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fac4d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bigrams(token_sequences, top_n=5):\n",
    "    bigram_counts = Counter()\n",
    "    total_bigrams = 0\n",
    "    for sentence in token_sequences:\n",
    "        if not sentence:\n",
    "            continue\n",
    "        normalized_tokens = [token.lower() for token in sentence]\n",
    "        sentence_bigrams = list(nltk.bigrams(normalized_tokens))\n",
    "        if not sentence_bigrams:\n",
    "            continue\n",
    "        bigram_counts.update(sentence_bigrams)\n",
    "        total_bigrams += len(sentence_bigrams)\n",
    "    if total_bigrams == 0:\n",
    "        return []\n",
    "    return [\n",
    "        (bigram, round(count / total_bigrams, 4))\n",
    "        for bigram, count in bigram_counts.most_common(top_n)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0832480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1 top-5 non-stem bigrams: [(('what', 'is'), 0.0128), (('is', 'the'), 0.0112), (('what', 'are'), 0.0102), (('how', 'do'), 0.0084), (('can', 'i'), 0.0067)]\n",
      "Question1 top-5 stem bigrams: [(('what', 'is'), 0.0128), (('is', 'the'), 0.0112), (('what', 'are'), 0.0102), (('how', 'do'), 0.0084), (('can', 'i'), 0.0067)]\n",
      "Question2 top-5 non-stem bigrams: [(('what', 'is'), 0.0123), (('is', 'the'), 0.0108), (('what', 'are'), 0.0098), (('how', 'do'), 0.0085), (('can', 'i'), 0.0068)]\n",
      "Question2 top-5 stem bigrams: [(('what', 'is'), 0.0123), (('is', 'the'), 0.0108), (('what', 'are'), 0.0098), (('how', 'do'), 0.0085), (('can', 'i'), 0.0068)]\n"
     ]
    }
   ],
   "source": [
    "q1_top_bigrams = get_top_bigrams(q1_tr_word_token)\n",
    "q1_top_stem_bigrams = get_top_bigrams(q1_tr_stem_token)\n",
    "q2_top_bigrams = get_top_bigrams(q2_tr_word_token)\n",
    "q2_top_stem_bigrams = get_top_bigrams(q2_tr_stem_token)\n",
    "\n",
    "print('Question1 top-5 non-stem bigrams:', q1_top_bigrams)\n",
    "print('Question1 top-5 stem bigrams:', q1_top_stem_bigrams)\n",
    "print('Question2 top-5 non-stem bigrams:', q2_top_bigrams)\n",
    "print('Question2 top-5 stem bigrams:', q2_top_stem_bigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936c3bf",
   "metadata": {},
   "source": [
    "### Task 3. Naïve Bayes Classifier (5.5 marks)\n",
    "\n",
    "The QQR dataset contains pairs of questions with labels indicating whether the two questions are semantically duplicate (1) or not (0).\n",
    "\n",
    "1. Using a Bag-of-Words representation, train a Naïve Bayes classifier to predict duplicates. (2 marks)\n",
    "\n",
    "1. Report accuracy, precision, and recall on the test set. (1.5 marks)\n",
    "\n",
    "1. Inspect your confusion matrix. Identify one type of error (false positive or false negative) that dominates. Suggest a possible reason for this pattern based on the dataset. (2 mark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "880092f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on, you are allowed to use a subset of the dataset which requires less computing resources.\n",
    "# Note that you have to use the same subset for the following coding tasks, which ensure fairness when comparing performance across different models.\n",
    "\n",
    "Ntrain = 1000\n",
    "Ntest = 100\n",
    "ds = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "# Use validation set as our test; optionally create a smaller train subset for speed\n",
    "train_ds = ds[\"train\"].select(range(Ntrain))\n",
    "eval_ds  = ds[\"validation\"].select(range(Ntest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d8e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (Ntrain=1000): 0.9800\n",
      "Test accuracy: 0.7400\n",
      "Precision: 0.6250\n",
      "Recall: 0.3333\n",
      "Confusion matrix: [[64  6]\n",
      " [20 10]]\n",
      "Dominant error type: false negatives (FP=6, FN=20). Duplicates with different wording slip through the bag-of-words features.\n"
     ]
    }
   ],
   "source": [
    "# Reuse the QQP validation slice as our fixed test set\n",
    "q1_test = list(eval_ds['question1'])\n",
    "q2_test = list(eval_ds['question2'])\n",
    "y_test = np.array(eval_ds['label'])\n",
    "\n",
    "# Use the entire training set for fitting\n",
    "q1_train = list(train_ds['question1'])\n",
    "q2_train = list(train_ds['question2'])\n",
    "y_train = np.array(train_ds['label'])\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "vectorizer.fit(q1_train + q2_train)\n",
    "\n",
    "X_train = hstack([\n",
    "    vectorizer.transform(q1_train),\n",
    "    vectorizer.transform(q2_train),\n",
    "])\n",
    "X_test = hstack([\n",
    "    vectorizer.transform(q1_test),\n",
    "    vectorizer.transform(q2_test),\n",
    "])\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "nb_train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "nb_vectorizer = vectorizer\n",
    "nb_clf = clf\n",
    "nb_preds = test_predictions\n",
    "\n",
    "nb_accuracy = accuracy_score(y_test, test_predictions)\n",
    "nb_precision = precision_score(y_test, test_predictions, zero_division=0)\n",
    "nb_recall = recall_score(y_test, test_predictions, zero_division=0)\n",
    "nb_confusion = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(f\"Training accuracy (Ntrain={Ntrain}): {nb_train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Precision: {nb_precision:.4f}\")\n",
    "print(f\"Recall: {nb_recall:.4f}\")\n",
    "print('Confusion matrix:', nb_confusion)\n",
    "\n",
    "fp, fn = nb_confusion[0, 1], nb_confusion[1, 0]\n",
    "if fn > fp:\n",
    "    dominant_error = 'false negatives'\n",
    "    explanation = 'Duplicates with different wording slip through the bag-of-words features.'\n",
    "elif fp > fn:\n",
    "    dominant_error = 'false positives'\n",
    "    explanation = 'Different questions that share surface words are mistaken as duplicates.'\n",
    "else:\n",
    "    dominant_error = 'balanced'\n",
    "    explanation = 'False positives and false negatives occur at similar rates.'\n",
    "\n",
    "print(f\"Dominant error type: {dominant_error} (FP={fp}, FN={fn}). {explanation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c15d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3: Visualise Naïve Bayes confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "class_labels = ['Non-duplicate', 'Duplicate']\n",
    "sns.heatmap(\n",
    "    nb_confusion, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=class_labels, yticklabels=class_labels\n",
    ")\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Naïve Bayes Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf16e2",
   "metadata": {},
   "source": [
    "### Task 4. Siamese Neural Network (7 marks)\n",
    "\n",
    "You now want to learn semantic similarity directly from the question pairs.\n",
    "\n",
    "1. Design a Siamese Neural Network with two identical LSTM encoders that embed each question. (3 marks)\n",
    "\n",
    "1. Use cosine similarity to classify duplicates, and report accuracy and F1-score. (2 marks)\n",
    "\n",
    "1. Compare your Siamese model to your Naïve Bayes model. Which one handles imbalanced errors (precision vs. recall) better in your results, and why do you think that is? (2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca4e3592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# --- Tokenizer ---\n",
    "TOKENIZER_NAME = \"bert-base-uncased\"\n",
    "TOKENIZER = BertTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size\n",
    "PAD_TOKEN_ID = TOKENIZER.pad_token_id\n",
    "\n",
    "# --- parameters ---\n",
    "MAX_LEN = 80\n",
    "EMBED_SIZE = 256\n",
    "LSTM_UNITS = 256\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "MARGIN = 1.0\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848440f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    # Dataset matches the practical: returns token ids and label per pair\n",
    "    def __init__(self, sents1, sents2, labels, tokenizer, max_len):\n",
    "        self.sents1 = sents1\n",
    "        self.sents2 = sents2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        q1_text = str(self.sents1[idx])\n",
    "        q2_text = str(self.sents2[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoded1 = self.tokenizer.encode_plus(\n",
    "            q1_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded2 = self.tokenizer.encode_plus(\n",
    "            q2_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids1': encoded1['input_ids'].flatten(),\n",
    "            'ids2': encoded2['input_ids'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac2f600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseDataset(list(train_ds['question1']), list(train_ds['question2']), train_ds['label'], TOKENIZER, MAX_LEN)\n",
    "test_dataset = SiameseDataset(list(eval_ds['question1']), list(eval_ds['question2']), eval_ds['label'], TOKENIZER, MAX_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "ecd0cadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the life of a math student? Could you describe your own experiences?\n",
      "Which level of prepration is enough for the exam jlpt5?\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ids1': tensor([ 101, 2129, 2003, 1996, 2166, 1997, 1037, 8785, 3076, 1029, 2071, 2017,\n",
       "         6235, 2115, 2219, 6322, 1029,  102,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " 'ids2': tensor([  101,  2029,  2504,  1997, 17463,  8156,  2003,  2438,  2005,  1996,\n",
       "         11360,  1046, 14277,  2102,  2629,  1029,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " 'labels': tensor(0.)}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(train_ds['question1'])[0])\n",
    "print(list(train_ds['question2'])[0])\n",
    "print(list(train_ds['label'])[0])\n",
    "a = train_dataset[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4c48da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(VOCAB_SIZE, EMBED_SIZE, padding_idx=PAD_TOKEN_ID)\n",
    "emb1 = embedding(a['ids1'])\n",
    "emb2 = embedding(a['ids2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0820d5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm1 = nn.LSTM(EMBED_SIZE, LSTM_UNITS, batch_first=True, bidirectional=True, num_layers=1)\n",
    "_, (hidden1, _) = lstm1(emb1)\n",
    "hidden1 = hidden1.unsqueeze(1)\n",
    "sentence_rep1 = torch.cat((hidden1[0], hidden1[1]), dim = 1)\n",
    "_, (hidden2, _) = lstm1(emb2)\n",
    "hidden2 = hidden2.unsqueeze(1)\n",
    "sentence_rep2 = torch.cat((hidden2[0], hidden2[1]), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "924adc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine = F.cosine_similarity(sentence_rep1, sentence_rep1, dim=1).unsqueeze(-1)\n",
    "cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394b5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Siamese architecture with shared LSTM encoders\n",
    "class SiameseNetwork(nn.Module):\n",
    "    # Shared bidirectional LSTM encodes both questions with identical weights\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, pad_idx=PAD_TOKEN_ID, embed_dim=EMBED_SIZE, hidden_size=LSTM_UNITS, dropout=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(dropout) if dropout is not None else None\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward_once(self, tokens):\n",
    "        embedded = self.embedding(tokens)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        sentence_rep = torch.cat((hidden[0], hidden[1]), dim=1)\n",
    "        if self.dropout is not None:\n",
    "            sentence_rep = self.dropout(sentence_rep)\n",
    "        return sentence_rep\n",
    "\n",
    "    def forward(self, q1, q2):\n",
    "        h1 = self.forward_once(q1)\n",
    "        h2 = self.forward_once(q2)\n",
    "        cosine = F.cosine_similarity(h1, h2, dim=1).unsqueeze(-1)\n",
    "        # Cosine similarity mirrors Task 4 requirement; MLP learns a decision boundary on top\n",
    "        logits = self.classifier(cosine).squeeze(-1)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8bbe855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimiser, criterion, device):\n",
    "    # End-to-end optimisation keeps gradients flowing into the shared encoder, unlike the two-stage practical\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        ids1 = batch['ids1'].to(device)\n",
    "        ids2 = batch['ids2'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        logits = model(ids1, ids2)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "38703138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        # Evaluation converts logits to probabilities to compute threshold-based metrics\n",
    "        for batch in loader:\n",
    "            ids1 = batch['ids1'].to(device)\n",
    "            ids2 = batch['ids2'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            logits = model(ids1, ids2)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "    preds = (np.array(all_probs) >= 0.5).astype(int)\n",
    "    labels_np = np.array(all_labels)\n",
    "    print(f\"probs: {all_probs}\")\n",
    "    print(f\"preds: {preds}\")\n",
    "    print(f\"gt: {labels_np}\")\n",
    "    accuracy = accuracy_score(labels_np, preds)\n",
    "    precision = precision_score(labels_np, preds, zero_division=0)\n",
    "    recall = recall_score(labels_np, preds, zero_division=0)\n",
    "    f1 = f1_score(labels_np, preds, zero_division=0)\n",
    "    return total_loss / len(loader), accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "49b0a991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = [0.3333, 0.88, 0.1234, 0.111, 0.5678, 0.9999, 0.0001]\n",
    "abc1 = (np.array(abc) >= 0.5).astype(int)\n",
    "abc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5d3b518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc2 = [1, 0, 0, 0, 1, 1, 0]\n",
    "accuracy_score(abc2, abc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1e5d243f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(abc2, abc1, zero_division=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f3425ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.6639\n",
      "Epoch 2: train loss=0.6566\n",
      "Epoch 3: train loss=0.6577\n",
      "Epoch 4: train loss=0.6519\n",
      "Epoch 5: train loss=0.6526\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "gt: [0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0.]\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Siamese LSTM with cosine head (Practical 10.2-inspired)\n",
    "\n",
    "model = SiameseNetwork(dropout=DROPOUT).to(device)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimiser, criterion, device)\n",
    "    print(f'Epoch {epoch}: train loss={train_loss:.4f}')\n",
    "    \n",
    "# Requirement 2: Cosine similarity head provides logits for metrics\n",
    "\n",
    "test_loss, siamese_accuracy, siamese_precision, siamese_recall, siamese_f1 = evaluate(\n",
    "# Final metrics feed the comparison cell and satisfy Task 4 reporting requirements\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f'Accuracy: {siamese_accuracy:.4f}')\n",
    "print(f'Precision: {siamese_precision:.4f}')\n",
    "print(f'Recall: {siamese_recall:.4f}')\n",
    "print(f'F1 score: {siamese_f1:.4f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "56683771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs: [0.38757359981536865, 0.38757550716400146, 0.38773444294929504, 0.387760728597641, 0.3875699043273926, 0.38757041096687317, 0.38764259219169617, 0.3877357840538025, 0.3875700533390045, 0.387582004070282, 0.38757020235061646, 0.3877199590206146, 0.3875699043273926, 0.38759884238243103, 0.3877299129962921, 0.38758328557014465, 0.38771235942840576, 0.38773009181022644, 0.38757020235061646, 0.38760894536972046, 0.38764914870262146, 0.3875699043273926, 0.38772839307785034, 0.3875967562198639, 0.38760748505592346, 0.3875702917575836, 0.3878251314163208, 0.3877429962158203, 0.3875699043273926, 0.38758385181427, 0.38768649101257324, 0.3877127468585968, 0.38766780495643616, 0.3875993490219116, 0.3876037299633026, 0.38759949803352356, 0.3877325654029846, 0.38773900270462036, 0.38758909702301025, 0.38757041096687317, 0.38756996393203735, 0.3876131772994995, 0.38766881823539734, 0.3876138925552368, 0.3876751959323883, 0.38757097721099854, 0.38757574558258057, 0.3876722753047943, 0.38757091760635376, 0.3878074288368225, 0.3876195549964905, 0.3877342939376831, 0.3875699043273926, 0.3875699043273926, 0.38781607151031494, 0.38769227266311646, 0.38768282532691956, 0.38770198822021484, 0.38761410117149353, 0.3877546191215515, 0.38778913021087646, 0.38757577538490295, 0.38778913021087646, 0.3875699043273926, 0.3876073956489563, 0.3875758647918701, 0.3875984251499176, 0.38762420415878296, 0.38761234283447266, 0.38760608434677124, 0.3875904679298401, 0.38756993412971497, 0.3878233730792999, 0.38768574595451355, 0.3875761032104492, 0.3877330422401428, 0.38756996393203735, 0.38767725229263306, 0.38758137822151184, 0.38759222626686096, 0.3875705897808075, 0.3875732719898224, 0.38756996393203735, 0.38791942596435547, 0.3876476585865021, 0.3878265917301178, 0.38761502504348755, 0.3875699043273926, 0.3875729441642761, 0.38758769631385803, 0.38773444294929504, 0.3876325190067291, 0.3875713646411896, 0.38757821917533875, 0.3875856399536133, 0.38760286569595337, 0.38776877522468567, 0.3877332806587219, 0.38757482171058655, 0.3875699043273926]\n",
      "preds: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "gt: [0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0.]\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Requirement 2: Cosine similarity head provides logits for metrics\n",
    "\n",
    "test_loss, siamese_accuracy, siamese_precision, siamese_recall, siamese_f1 = evaluate(\n",
    "# Final metrics feed the comparison cell and satisfy Task 4 reporting requirements\n",
    "    model, test_loader, criterion, device\n",
    ")\n",
    "\n",
    "print(f'Accuracy: {siamese_accuracy:.4f}')\n",
    "print(f'Precision: {siamese_precision:.4f}')\n",
    "print(f'Recall: {siamese_recall:.4f}')\n",
    "print(f'F1 score: {siamese_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3a4fb21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes test accuracy: 0.7400\n",
      "Siamese accuracy: 0.5200, precision: 0.3548, recall: 0.7333, F1: 0.4783\n",
      "Siamese model recovers more paraphrases (higher recall) than Naïve Bayes, at the cost of precision.\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Quick comparison to Naïve Bayes baseline\n",
    "# Requirement 3: Compare Siamese metrics against Naive Bayes baseline\n",
    "# We contrast both models to explain precision/recall trade-offs, per assignment prompt\n",
    "print(f\"Naïve Bayes test accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Siamese accuracy: {siamese_accuracy:.4f}, precision: {siamese_precision:.4f}, recall: {siamese_recall:.4f}, F1: {siamese_f1:.4f}\")\n",
    "if siamese_recall > nb_recall:\n",
    "    print('Siamese model recovers more paraphrases (higher recall) than Naïve Bayes, at the cost of precision.')\n",
    "else:\n",
    "    print('Siamese model maintains higher precision but misses more paraphrases than Naïve Bayes.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cf68de",
   "metadata": {},
   "source": [
    "### Task 5. Transformer-Based Classifier (10 marks)\n",
    "\n",
    "Instead of handcrafted features or LSTMs, you now fine-tune a pre-trained Transformer (e.g., BERT or RoBERTa, etc) for QQP.\n",
    "\n",
    "1. Fine-tune the model for 3 epochs with learning rate 2e-5. (3 marks)\n",
    "\n",
    "1. Report the accuracy, precision, recall, and F1-score. (2 marks)\n",
    "\n",
    "1. Compare your Transformer results with your Siamese model. Did the Transformer improve both precision and recall, or mainly one? What does this suggest about how it captures question meaning? (2 marks)\n",
    "\n",
    "1. Look at one example your Transformer misclassified. Write a short explanation of why the model might have made this mistake. (3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "309af6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3420",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
