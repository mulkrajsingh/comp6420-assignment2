{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52314ed0",
   "metadata": {},
   "source": [
    "# Assignment 2: Python for Text Processing\n",
    "\n",
    "**Submission deadline:** Friday, 31 Oct 2025, 11:55 PM  \n",
    "**Assessment marks:** 35 marks (35% of the total unit assessment)\n",
    "\n",
    "---\n",
    "\n",
    "### Late Submission Penalty\n",
    "\n",
    "Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted.\n",
    "\n",
    "> **Example:** If the assignment is worth 8 marks (of the entire unit) and your submission is late by 19 hours (or 23 hours 59 minutes 59 seconds), 0.4 marks (5% of 8 marks) will be deducted. If your submission is late by 24 hours (or 47 hours 59 minutes 59 seconds), 0.8 marks (10% of 8 marks) will be deducted, and so on.\n",
    "\n",
    "The submission time for all uploaded assessments is **11:55 PM**. A **1-hour grace period** is provided for technical concerns.  Apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration), if you think you should be granted an extended deadline or waive the late submission penalty. You should apply immediately when the situation occurs.\n",
    "\n",
    "---\n",
    "\n",
    "### Academic Integrity\n",
    "\n",
    "All submitted work must be your own. For rules around AI tools, refer to **\"Using Generative AI Tools\" on iLearn**.\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "* Complete the five tasks below.\n",
    "\n",
    "* Write your code and comments inside this notebook.\n",
    "\n",
    "* Your notebook must include the running outputs of your final code.\n",
    "\n",
    "* **Submit this `.ipynb` file, containing your code and outputs, to iLearn.**\n",
    "\n",
    "---\n",
    "\n",
    "### Assessment\n",
    "\n",
    "-  Marks are based on the correctness of your code, outputs, and coding style.\n",
    "-  A total of **2.5 marks** (0.5 per task) are awarded globally across the assignment for both of the below: (1) runnable codes; (2) good coding style: clean, modular code, meaningful variable names, and good comments.\n",
    "-  If outputs are missing or incorrect, up to **25% of the marks for that task** can be deducted.\n",
    "-  See each task below for the detailed mark breakdown.\n",
    "\n",
    "---\n",
    "\n",
    "### AI Tools Usage Policy\n",
    "\n",
    "\n",
    "In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and what you cannot do, please visit these information pages provided by Macquarie University.\n",
    "\n",
    "- See: [Artificial Intelligence Tools and Academic Integrity in FSE](https://bit.ly/3uxgQP4)\n",
    "\n",
    "If you choose to use these tools, make the following explicit in your submitted file as comments starting with \"Use of AI generators in this assignment\" :\n",
    "\n",
    "- What part of your code is based on the output of such tools,\n",
    "- What tools you used,\n",
    "- What prompts you used to generate the code or text, and\n",
    "- What modifications you made on the generated code or text?\n",
    "\n",
    "This will help us assess your work fairly. \n",
    "\n",
    "**If we observe that you have used an AI generator and you do not give the above information, you may face disciplinary action.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde6c533",
   "metadata": {},
   "source": [
    "\n",
    "## Objectives of this assignment\n",
    "\n",
    "In this assignment, you will work on the Quora Question Pairs (QQP) datset detailed below. The first two tasks will help you get familiar with the data, and the remaining requires you to implement deep neural networks.\n",
    "\n",
    "\n",
    "**About the Quora Question Pairs (QQP) Dataset**\n",
    "\n",
    "Description: A large dataset of 400k+ question pairs from Quora, labeled whether they are duplicates (semantically the same) or not. It features informal, noisy text with class imbalance, hard positives (low lexical overlap) and hard negatives (high overlap, different meaning). QQP is practically relevant for deduplicating FAQs, search, and support systems. Working on QQP builds transferable skills, such as text preprocessing, model comparison, threshold tuning, error analysis, and deployment-minded reasoning about real applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4113f16",
   "metadata": {},
   "source": [
    "**Get familiar with the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d3b74181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip -q install datasets    # Install the datasets package to access the dataset\n",
    "# add the packages you used, and specify the verion you installed\n",
    "\n",
    "# All required import for the assignment.\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "49aa8a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is: mps\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Selecting the device to run the model on.\n",
    "cuda - Nvidia GPU\n",
    "mps - Apple M1 GPU\n",
    "cpu - CPU of the device\n",
    "'''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(\"The device is:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "26cf6511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x302e46450>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 7\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c55f743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load QQP\n",
    "ds = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "# Use validation set as our test; optionally create a smaller train subset for speed\n",
    "train_ds = ds[\"train\"]\n",
    "eval_ds  = ds[\"validation\"]\n",
    "\n",
    "q1_tr = list(train_ds[\"question1\"])\n",
    "q2_tr = list(train_ds[\"question2\"])\n",
    "y_tr  = np.array(train_ds[\"label\"])\n",
    "\n",
    "q1_te = list(eval_ds[\"question1\"])\n",
    "q2_te = list(eval_ds[\"question2\"])\n",
    "y_te  = np.array(eval_ds[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05743951",
   "metadata": {},
   "source": [
    "### Task 1. What is the top-5 common NOUN in the question1 and question2, respectively? (5 marks)\n",
    "\n",
    "Write codes that returns the top-5 common NOUN in the questions. To find the part of speech, use NLTK's \"Universal\" tag set. You may need to use NLTK's `sent_tokenize` and `word_tokenize` to get words. The function returns a list that is descendingly sorted according to freqency, e.g. [(noun1, 22), (noun2, 10), ...].\n",
    "<!-- To produce the correct results, the function must do this.  -->\n",
    "Hint: The following steps will produce the correct results:\n",
    "\n",
    "- Concatenate all questions together.\n",
    "- Use the NLTK libraries to find the tokens and the stems.\n",
    "- Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "- Use NLTK's part of speech tagger, using the \"Universal\" tagset.\n",
    "- Use NLTK's `pos_tag_sents` instead of `pos_tag`.\n",
    "\n",
    "Marking Criteria: \n",
    "- 2.5 marks for the correct codes and results of each column, namely question1 and question2 columns.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "efc8fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_tokens(data):\n",
    "    '''\n",
    "    Tokenizes the input data into word tokens.\n",
    "    Args:\n",
    "        data (list): A list of strings to be tokenized.\n",
    "    Returns:\n",
    "        list: A list of lists, where each sublist contains word tokens of a sentence.\n",
    "\n",
    "    Joins the list of sentences into a single string, then splits it into sentences,\n",
    "    and finally tokenizes each sentence into words.\n",
    "    '''\n",
    "    sep = ' '\n",
    "    joined_data = sep.join(data)\n",
    "    wt = [nltk.word_tokenize(s) for s in nltk.sent_tokenize(joined_data)]\n",
    "    return wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0a2d0eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "stemmer = nltk.PorterStemmer()\n",
    "\n",
    "def get_stems(word_tokens):\n",
    "    '''\n",
    "    Stems the word tokens using Porter Stemmer.\n",
    "    Args:\n",
    "        word_tokens (list): A list of lists, where each sublist contains word tokens of a sentence.\n",
    "    Returns:\n",
    "        list: A list of lists, where each sublist contains stemmed word tokens of a sentence.\n",
    "    '''\n",
    "    return [[stemmer.stem(token.lower()) for token in sentence] for sentence in word_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed073470",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tagged_words(word_token):\n",
    "    '''\n",
    "    Tags the word tokens with their respective parts of speech using \"universal\" tagset.\n",
    "    Args:\n",
    "        word_token (list): A list of lists, where each sublist contains word tokens of a sentence.\n",
    "    Returns:\n",
    "        list: A list of lists, where each sublist contains tuples of word tokens and their POS tags.\n",
    "    '''\n",
    "    tagged_words_list = nltk.pos_tag_sents(word_token, tagset='universal')\n",
    "    return tagged_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bb05fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_nouns(tagged_words_list, n_top=5):\n",
    "    '''\n",
    "    Finds the most common nouns in the tagged words list.\n",
    "    Args:\n",
    "        tagged_words_list (list): A list of lists, where each sublist contains tuples of word tokens and their POS tags.\n",
    "        n_top (int): The number of most common nouns to return.\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a noun and its frequency.\n",
    "    '''\n",
    "    tagged_nouns = [\n",
    "        stemmer.stem(tagged_word[0].lower())\n",
    "        for tagged_words in tagged_words_list\n",
    "        for tagged_word in tagged_words\n",
    "        if tagged_word[1] == 'NOUN'\n",
    "    ]\n",
    "    noun_counter = Counter(tagged_nouns)\n",
    "    return noun_counter.most_common(n_top)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "dfddf5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tr_word_token = get_word_tokens(q1_tr)\n",
    "q2_tr_word_token = get_word_tokens(q2_tr)\n",
    "\n",
    "q1_tr_stem_token = get_stems(q1_tr_word_token)\n",
    "q2_tr_stem_token = get_stems(q2_tr_word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "57ef8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_tr_tagged_words = get_tagged_words(q1_tr_word_token)\n",
    "q2_tr_tagged_words = get_tagged_words(q2_tr_word_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0659501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 most common nouns in question1: [('india', 12708), ('peopl', 11507), ('way', 10598), ('differ', 8623), ('quora', 7678)]\n",
      "Top 5 most common nouns in question2: [('india', 13491), ('peopl', 12281), ('way', 11900), ('quora', 7967), ('time', 7579)]\n"
     ]
    }
   ],
   "source": [
    "most_common_nouns_in_q1 = get_most_common_nouns(q1_tr_tagged_words)\n",
    "most_common_nouns_in_q2 = get_most_common_nouns(q2_tr_tagged_words)\n",
    "\n",
    "print('Top 5 most common nouns in question1:', most_common_nouns_in_q1)\n",
    "print('Top 5 most common nouns in question2:', most_common_nouns_in_q2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ac4b3",
   "metadata": {},
   "source": [
    "### Task 2. What are the top-5 common stem 2-grams and non-stem 2-grams for question1 and question2, respectively? (5 marks)\n",
    "\n",
    "Write codes that returns the top-5 most frequent 2-grams (bigrams) of stemmed and non-stemmed tokens along with their normalized frequency from the question1 and question2 columns of the QQP dataset. The output should be in descending order of frequency, **with frequencies normalized by the total number of bigrams (rounded to 4 decimal places)**, e.g., `[(('what', 'is'), 0.0105), (('what', 'are'), 0.0053), ...]`.\n",
    "\n",
    "<!-- To produce the correct results, the function must do this: -->\n",
    "\n",
    "Hint: The following steps will produce the correct results:\n",
    "\n",
    "- Concatenate all questions together.\n",
    "- Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "- Use the NLTK libraries to find the tokens and the stems.\n",
    "- Use NLTK's Porter stemmer to get the root words.\n",
    "- Round normalized frequency to 4 precision after the decimal point.\n",
    "- When computing bigrams, do not consider words that are in different sentences. For example, if we have this text: `Sentence 1. And sentence 2.` the bigrams are: `('Sentence','1'), ('1','.'), ('.','And'), ('And','sentence')`, etc. Note that the following would not be a valid bigram, since the punctuation mark and the word \"And\" are in different sentences: `('.','And')`.\n",
    "\n",
    "Marking Criteria: \n",
    "- 2.5 marks for the correct codes and restuls of each column, namely question1 and question2 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_bigrams(token_sequences, top_n=5):\n",
    "    '''\n",
    "    Computes the top N most common bigrams from the token sequences.\n",
    "    Args:\n",
    "        token_sequences (list): A list of lists, where each sublist contains word tokens of a sentence.\n",
    "        top_n (int): The number of most common bigrams to return.\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains a bigram (as a tuple of two words) and its relative frequency.\n",
    "    '''\n",
    "\n",
    "    bigram_counts = Counter()\n",
    "    total_bigrams = 0\n",
    "    for sentence in token_sequences:\n",
    "        if not sentence:\n",
    "            continue\n",
    "        normalized_tokens = [token.lower() for token in sentence]\n",
    "        sentence_bigrams = list(nltk.bigrams(normalized_tokens))\n",
    "        if not sentence_bigrams:\n",
    "            continue\n",
    "        bigram_counts.update(sentence_bigrams)\n",
    "        total_bigrams += len(sentence_bigrams)\n",
    "    if total_bigrams == 0:\n",
    "        return []\n",
    "    return [\n",
    "        (bigram, round(count / total_bigrams, 4))\n",
    "        for bigram, count in bigram_counts.most_common(top_n)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2c61e8",
   "metadata": {},
   "source": [
    "We reuse the cached token lists to compute stemmed and non-stemmed bigram statistics for each question column, then print them in descending order as required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0832480b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1 top-5 non-stem bigrams: [(('what', 'is'), 0.0128), (('is', 'the'), 0.0112), (('what', 'are'), 0.0102), (('how', 'do'), 0.0084), (('can', 'i'), 0.0067)]\n",
      "Question1 top-5 stem bigrams: [(('what', 'is'), 0.0128), (('is', 'the'), 0.0112), (('what', 'are'), 0.0102), (('how', 'do'), 0.0084), (('can', 'i'), 0.0067)]\n",
      "Question2 top-5 non-stem bigrams: [(('what', 'is'), 0.0123), (('is', 'the'), 0.0108), (('what', 'are'), 0.0098), (('how', 'do'), 0.0085), (('can', 'i'), 0.0068)]\n",
      "Question2 top-5 stem bigrams: [(('what', 'is'), 0.0123), (('is', 'the'), 0.0108), (('what', 'are'), 0.0098), (('how', 'do'), 0.0085), (('can', 'i'), 0.0068)]\n"
     ]
    }
   ],
   "source": [
    "q1_top_bigrams = get_top_bigrams(q1_tr_word_token)\n",
    "q1_top_stem_bigrams = get_top_bigrams(q1_tr_stem_token)\n",
    "q2_top_bigrams = get_top_bigrams(q2_tr_word_token)\n",
    "q2_top_stem_bigrams = get_top_bigrams(q2_tr_stem_token)\n",
    "\n",
    "print('Question1 top-5 non-stem bigrams:', q1_top_bigrams)\n",
    "print('Question1 top-5 stem bigrams:', q1_top_stem_bigrams)\n",
    "print('Question2 top-5 non-stem bigrams:', q2_top_bigrams)\n",
    "print('Question2 top-5 stem bigrams:', q2_top_stem_bigrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936c3bf",
   "metadata": {},
   "source": [
    "### Task 3. Naïve Bayes Classifier (5.5 marks)\n",
    "\n",
    "The QQR dataset contains pairs of questions with labels indicating whether the two questions are semantically duplicate (1) or not (0).\n",
    "\n",
    "1. Using a Bag-of-Words representation, train a Naïve Bayes classifier to predict duplicates. (2 marks)\n",
    "\n",
    "1. Report accuracy, precision, and recall on the test set. (1.5 marks)\n",
    "\n",
    "1. Inspect your confusion matrix. Identify one type of error (false positive or false negative) that dominates. Suggest a possible reason for this pattern based on the dataset. (2 mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b9ee61",
   "metadata": {},
   "source": [
    "To keep every model comparable and quick to run locally, we cap the QQP dataset to 1k training and 100 validation examples. The same slice is reused across Tasks 3-5 per the assignment instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "880092f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From now on, you are allowed to use a subset of the dataset which requires less computing resources.\n",
    "# Note that you have to use the same subset for the following coding tasks, which ensure fairness when comparing performance across different models.\n",
    "\n",
    "Ntrain = 1000\n",
    "Ntest = 100\n",
    "ds = load_dataset(\"glue\", \"qqp\")\n",
    "\n",
    "# Use validation set as our test; optionally create a smaller train subset for speed\n",
    "train_ds = ds[\"train\"].select(range(Ntrain))\n",
    "eval_ds  = ds[\"validation\"].select(range(Ntest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733ee94",
   "metadata": {},
   "source": [
    "This block builds a bag-of-words representation for both questions, fits the Naïve Bayes classifier, and records the metrics we will later compare against neural models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d8e9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy (Ntrain=1000): 0.9800\n",
      "Test accuracy: 0.7400\n",
      "Precision: 0.6250\n",
      "Recall: 0.3333\n",
      "Confusion matrix: [[64  6]\n",
      " [20 10]]\n",
      "Dominant error type: false negatives (FP=6, FN=20). Duplicates with different wording slip through the bag-of-words features.\n"
     ]
    }
   ],
   "source": [
    "# Reuse the QQP validation slice as our fixed test set\n",
    "q1_test = list(eval_ds['question1'])\n",
    "q2_test = list(eval_ds['question2'])\n",
    "y_test = np.array(eval_ds['label'])\n",
    "\n",
    "# Use the entire training set for fitting\n",
    "q1_train = list(train_ds['question1'])\n",
    "q2_train = list(train_ds['question2'])\n",
    "y_train = np.array(train_ds['label'])\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "vectorizer.fit(q1_train + q2_train)\n",
    "\n",
    "X_train = hstack([\n",
    "    vectorizer.transform(q1_train),\n",
    "    vectorizer.transform(q2_train),\n",
    "])\n",
    "X_test = hstack([\n",
    "    vectorizer.transform(q1_test),\n",
    "    vectorizer.transform(q2_test),\n",
    "])\n",
    "\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "train_predictions = clf.predict(X_train)\n",
    "nb_train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "test_predictions = clf.predict(X_test)\n",
    "\n",
    "nb_vectorizer = vectorizer\n",
    "nb_clf = clf\n",
    "nb_preds = test_predictions\n",
    "\n",
    "nb_accuracy = accuracy_score(y_test, test_predictions)\n",
    "nb_precision = precision_score(y_test, test_predictions, zero_division=0)\n",
    "nb_recall = recall_score(y_test, test_predictions, zero_division=0)\n",
    "nb_confusion = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "print(f\"Training accuracy (Ntrain={Ntrain}): {nb_train_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Precision: {nb_precision:.4f}\")\n",
    "print(f\"Recall: {nb_recall:.4f}\")\n",
    "print('Confusion matrix:', nb_confusion)\n",
    "\n",
    "fp, fn = nb_confusion[0, 1], nb_confusion[1, 0]\n",
    "if fn > fp:\n",
    "    dominant_error = 'false negatives'\n",
    "    explanation = 'Duplicates with different wording slip through the bag-of-words features.'\n",
    "elif fp > fn:\n",
    "    dominant_error = 'false positives'\n",
    "    explanation = 'Different questions that share surface words are mistaken as duplicates.'\n",
    "else:\n",
    "    dominant_error = 'balanced'\n",
    "    explanation = 'False positives and false negatives occur at similar rates.'\n",
    "\n",
    "print(f\"Dominant error type: {dominant_error} (FP={fp}, FN={fn}). {explanation}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c88970f",
   "metadata": {},
   "source": [
    "Visualising the confusion matrix helps explain whether false positives or false negatives dominate, addressing the error-analysis requirement for Task 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c15d52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 3: Visualise Naïve Bayes confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "class_labels = ['Non-duplicate', 'Duplicate']\n",
    "sns.heatmap(\n",
    "    nb_confusion, annot=True, fmt='d', cmap='Blues',\n",
    "    xticklabels=class_labels, yticklabels=class_labels\n",
    ")\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Naïve Bayes Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbf16e2",
   "metadata": {},
   "source": [
    "### Task 4. Siamese Neural Network (7 marks)\n",
    "\n",
    "You now want to learn semantic similarity directly from the question pairs.\n",
    "\n",
    "1. Design a Siamese Neural Network with two identical LSTM encoders that embed each question. (3 marks)\n",
    "\n",
    "1. Use cosine similarity to classify duplicates, and report accuracy and F1-score. (2 marks)\n",
    "\n",
    "1. Compare your Siamese model to your Naïve Bayes model. Which one handles imbalanced errors (precision vs. recall) better in your results, and why do you think that is? (2 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f907f5c0",
   "metadata": {},
   "source": [
    "For the Siamese network we set up a shared tokenizer and hyperparameters that mirror the practical, ensuring both question branches see consistent input lengths and embedding sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "63294c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# --- Tokenizer ---\n",
    "TOKENIZER_NAME = \"bert-base-uncased\"\n",
    "TOKENIZER = BertTokenizer.from_pretrained(TOKENIZER_NAME)\n",
    "VOCAB_SIZE = TOKENIZER.vocab_size\n",
    "PAD_TOKEN_ID = TOKENIZER.pad_token_id\n",
    "\n",
    "# --- parameters ---\n",
    "MAX_LEN = 80\n",
    "EMBED_SIZE = 256\n",
    "LSTM_UNITS = 256\n",
    "BATCH_SIZE = 25\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3\n",
    "MARGIN = 1.0\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecec8ab",
   "metadata": {},
   "source": [
    "The custom dataset prepares paired tensors for each question. Packaging both questions together keeps the training loop simple and guarantees the Siamese encoders receive identical preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ee5d377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseDataset(Dataset):\n",
    "    # Dataset matches the practical: returns token ids and label per pair\n",
    "    def __init__(self, sents1, sents2, labels, tokenizer, max_len):\n",
    "        self.sents1 = sents1\n",
    "        self.sents2 = sents2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        q1_text = str(self.sents1[idx])\n",
    "        q2_text = str(self.sents2[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoded1 = self.tokenizer.encode_plus(\n",
    "            q1_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        encoded2 = self.tokenizer.encode_plus(\n",
    "            q2_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ids1': encoded1['input_ids'].flatten(),\n",
    "            'ids2': encoded2['input_ids'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef44e8a",
   "metadata": {},
   "source": [
    "Our Siamese model shares an embedding + LSTM encoder between the two questions, then scores their cosine similarity through a small classifier head to produce logits for duplicate prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "557ebb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirement 1: Siamese architecture with shared LSTM encoders\n",
    "class SiameseNetwork(nn.Module):\n",
    "    # Shared bidirectional LSTM encodes both questions with identical weights\n",
    "    def __init__(self, vocab_size=VOCAB_SIZE, pad_idx=PAD_TOKEN_ID, embed_dim=EMBED_SIZE, hidden_size=LSTM_UNITS, dropout=DROPOUT):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_size, batch_first=True, bidirectional=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 1)\n",
    "        )\n",
    "\n",
    "    def forward_once(self, tokens):\n",
    "        embedded = self.embedding(tokens)\n",
    "        _, (hidden, _) = self.lstm(embedded)\n",
    "        return self.dropout(hidden[0])\n",
    "        \n",
    "\n",
    "    def forward(self, q1, q2):\n",
    "        h1 = self.forward_once(q1)\n",
    "        h2 = self.forward_once(q2)\n",
    "        cosine = F.cosine_similarity(h1, h2, dim=1).unsqueeze(-1)\n",
    "        logits = self.classifier(cosine).squeeze(-1)\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b5dde",
   "metadata": {},
   "source": [
    "Training and evaluation helpers encapsulate the optimisation loop. Keeping these utilities separate from the cell that instantiates the model keeps the notebook tidy and highlights the workflow steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "257b8b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimiser, criterion, device):\n",
    "    # End-to-end optimisation keeps gradients flowing into the shared encoder, unlike the two-stage practical\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in loader:\n",
    "        ids1 = batch['ids1'].to(device)\n",
    "        ids2 = batch['ids2'].to(device)\n",
    "        labels = batch['labels'].float().to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        logits = model(ids1, ids2)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb07fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_probs, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        # Evaluation converts logits to probabilities to compute threshold-based metrics\n",
    "        for batch in loader:\n",
    "            ids1 = batch['ids1'].to(device)\n",
    "            ids2 = batch['ids2'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "\n",
    "            logits = model(ids1, ids2)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            \n",
    "            all_probs.extend(probs.cpu().numpy().tolist())\n",
    "            all_labels.extend(labels.cpu().numpy().tolist())\n",
    "\n",
    "    preds = (np.array(all_probs) >= 0.5).astype(float)\n",
    "    labels_np = np.array(all_labels)\n",
    "\n",
    "    print('preds === ', preds)\n",
    "    print('lablessfasd === ', labels_np)\n",
    "\n",
    "    accuracy = accuracy_score(labels_np, preds)\n",
    "    precision = precision_score(labels_np, preds, zero_division=0)\n",
    "    recall = recall_score(labels_np, preds, zero_division=0)\n",
    "    f1 = f1_score(labels_np, preds, zero_division=0)\n",
    "    return total_loss / len(loader), accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c150bb",
   "metadata": {},
   "source": [
    "Here we wrap the dataset objects in PyTorch DataLoaders so batching and shuffling match the expectations of the training helpers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "430dc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SiameseDataset(train_ds['question1'], train_ds['question2'], train_ds['label'], TOKENIZER, MAX_LEN)\n",
    "test_dataset = SiameseDataset(eval_ds['question1'], eval_ds['question2'], eval_ds['label'], TOKENIZER, MAX_LEN)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c7e522",
   "metadata": {},
   "source": [
    "This cell runs the Siamese training loop, reporting loss per epoch so we can confirm the model is learning before evaluating it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125327f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train loss=0.7163\n",
      "Epoch 2: train loss=0.6796\n",
      "Epoch 3: train loss=0.6601\n",
      "Epoch 4: train loss=0.6525\n",
      "Epoch 5: train loss=0.6500\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Siamese LSTM with cosine head (Practical 10.2-inspired)\n",
    "\n",
    "model = SiameseNetwork().to(DEVICE)\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    train_loss = train_epoch(model, train_loader, optimiser, criterion, DEVICE)\n",
    "    print(f'Epoch {epoch}: train loss={train_loss:.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7766ee",
   "metadata": {},
   "source": [
    "After training we compute accuracy, precision, recall, and F1 to satisfy Task 4's reporting requirement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6d935b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds ===  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "lablessfasd ===  [0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0.\n",
      " 0. 0. 1. 0.]\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 score: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Requirement 2: Cosine similarity head provides logits for metrics\n",
    "\n",
    "test_loss, siamese_accuracy, siamese_precision, siamese_recall, siamese_f1 = evaluate(\n",
    "# Final metrics feed the comparison cell and satisfy Task 4 reporting requirements\n",
    "    model, test_loader, criterion, DEVICE\n",
    ")\n",
    "\n",
    "print(f'Accuracy: {siamese_accuracy:.4f}')\n",
    "print(f'Precision: {siamese_precision:.4f}')\n",
    "print(f'Recall: {siamese_recall:.4f}')\n",
    "print(f'F1 score: {siamese_f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3d89a",
   "metadata": {},
   "source": [
    "Finally we compare the Siamese metrics against the Naïve Bayes baseline to discuss how each model handles the precision/recall trade-off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "4e7c7efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes test accuracy: 0.7400\n",
      "Siamese accuracy: 0.7000, precision: 0.0000, recall: 0.0000, F1: 0.0000\n",
      "Siamese model maintains higher precision but misses more paraphrases than Naïve Bayes.\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Quick comparison to Naïve Bayes baseline\n",
    "# Requirement 3: Compare Siamese metrics against Naive Bayes baseline\n",
    "# We contrast both models to explain precision/recall trade-offs, per assignment prompt\n",
    "print(f\"Naïve Bayes test accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\"Siamese accuracy: {siamese_accuracy:.4f}, precision: {siamese_precision:.4f}, recall: {siamese_recall:.4f}, F1: {siamese_f1:.4f}\")\n",
    "if siamese_recall > nb_recall:\n",
    "    print('Siamese model recovers more paraphrases (higher recall) than Naïve Bayes, at the cost of precision.')\n",
    "else:\n",
    "    print('Siamese model maintains higher precision but misses more paraphrases than Naïve Bayes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a7c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36cf68de",
   "metadata": {},
   "source": [
    "### Task 5. Transformer-Based Classifier (10 marks)\n",
    "\n",
    "Instead of handcrafted features or LSTMs, you now fine-tune a pre-trained Transformer (e.g., BERT or RoBERTa, etc) for QQP.\n",
    "\n",
    "1. Fine-tune the model for 3 epochs with learning rate 2e-5. (3 marks)\n",
    "\n",
    "1. Report the accuracy, precision, recall, and F1-score. (2 marks)\n",
    "\n",
    "1. Compare your Transformer results with your Siamese model. Did the Transformer improve both precision and recall, or mainly one? What does this suggest about how it captures question meaning? (2 marks)\n",
    "\n",
    "1. Look at one example your Transformer misclassified. Write a short explanation of why the model might have made this mistake. (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d321ec",
   "metadata": {},
   "source": [
    "Task 5 switches to a Transformer encoder. We load the pretrained BERT tokenizer and record the fine-tuning hyperparameters specified in the brief.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef4aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_MODEL_NAME = 'bert-base-uncased'\n",
    "TRANSFORMER_EPOCHS = 3\n",
    "TRANSFORMER_LR = 2e-5\n",
    "TRANSFORMER_BATCH_SIZE = 16\n",
    "TRANSFORMER_MAX_LEN = 128\n",
    "\n",
    "transformer_tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL_NAME)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f420197",
   "metadata": {},
   "source": [
    "Next we map the QQP subset through the tokenizer, keeping text copies for later error analysis while formatting tensors for PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2c148f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_transformer(batch):\n",
    "    return transformer_tokenizer(\n",
    "        batch['question1'],\n",
    "        batch['question2'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=TRANSFORMER_MAX_LEN,\n",
    "    )\n",
    "\n",
    "val_text_pairs = list(zip(eval_ds['question1'], eval_ds['question2']))\n",
    "\n",
    "tokenized_train = train_ds.map(\n",
    "    tokenize_transformer,\n",
    "    batched=True,\n",
    "    remove_columns=['question1', 'question2', 'idx'],\n",
    ")\n",
    "tokenized_eval = eval_ds.map(\n",
    "    tokenize_transformer,\n",
    "    batched=True,\n",
    "    remove_columns=['question1', 'question2', 'idx'],\n",
    ")\n",
    "\n",
    "tokenized_train = tokenized_train.rename_column('label', 'labels')\n",
    "tokenized_eval = tokenized_eval.rename_column('label', 'labels')\n",
    "\n",
    "model_input_cols = ['input_ids', 'attention_mask', 'labels']\n",
    "if 'token_type_ids' in tokenized_train.features:\n",
    "    model_input_cols.insert(2, 'token_type_ids')\n",
    "\n",
    "tokenized_train.set_format(type='torch', columns=model_input_cols)\n",
    "tokenized_eval.set_format(type='torch', columns=model_input_cols)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69396c95",
   "metadata": {},
   "source": [
    "We wrap the tokenised datasets in DataLoaders and instantiate the classification head from the pretrained BERT checkpoint, wiring up the AdamW optimiser and linear schedule required for stable fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dce015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(tokenized_train, batch_size=TRANSFORMER_BATCH_SIZE, shuffle=True)\n",
    "eval_loader = DataLoader(tokenized_eval, batch_size=TRANSFORMER_BATCH_SIZE)\n",
    "transformer_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    TRANSFORMER_MODEL_NAME,\n",
    "    num_labels=2,\n",
    ").to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr=TRANSFORMER_LR)\n",
    "total_training_steps = len(train_loader) * TRANSFORMER_EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=max(1, int(0.1 * total_training_steps)),\n",
    "    num_training_steps=total_training_steps,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba680e",
   "metadata": {},
   "source": [
    "This training loop fine-tunes BERT for exactly three epochs, echoing the assignment specification and letting us monitor convergence via the average loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6548daea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - loss: 0.6370\n",
      "Epoch 2/3 - loss: 0.4634\n",
      "Epoch 3/3 - loss: 0.3241\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, TRANSFORMER_EPOCHS + 1):\n",
    "    transformer_model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        batch = {key: value.to(DEVICE) for key, value in batch.items()}\n",
    "        outputs = transformer_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss += loss.item()\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    print(f'Epoch {epoch}/{TRANSFORMER_EPOCHS} - loss: {avg_epoch_loss:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720434d",
   "metadata": {},
   "source": [
    "The evaluation cell gathers the required metrics, contrasts them with the Siamese results when available, and logs the first misclassified pair alongside a short explanation of the error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a301dc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer accuracy: 0.7700\n",
      "Transformer precision: 0.6207\n",
      "Transformer recall: 0.6000\n",
      "Transformer F1 score: 0.6102\n",
      "Siamese precision: 0.0000, recall: 0.0000\n",
      "Transformer improves both precision and recall, indicating stronger capture of question meaning.\n",
      "Misclassified example:\n",
      "Question 1: What are some good baby girl names starting with D?\n",
      "Question 2: What are some good baby girl names starting with D or H?\n",
      "True label: 0 - Predicted: 1\n",
      "Possible reason: The questions share almost all tokens, so the model fixates on lexical overlap and misses that the second query broadens to names starting with D or H, turning the pair into a near-duplicate despite different intent.\n"
     ]
    }
   ],
   "source": [
    "transformer_model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "misclassified_idx = None\n",
    "misclassified_pred = None\n",
    "misclassified_true = None\n",
    "example_idx = 0\n",
    "\n",
    "default_eval_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in eval_loader:\n",
    "        labels = batch['labels']\n",
    "        batch_on_device = {key: value.to(DEVICE) for key, value in batch.items()}\n",
    "        outputs = transformer_model(**batch_on_device)\n",
    "        default_eval_loss += outputs.loss.item()\n",
    "        batch_preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "        labels_np = labels.numpy()\n",
    "        all_preds.extend(batch_preds.tolist())\n",
    "        all_labels.extend(labels_np.tolist())\n",
    "        for pred, true in zip(batch_preds, labels_np):\n",
    "            if misclassified_idx is None and pred != true:\n",
    "                misclassified_idx = example_idx\n",
    "                misclassified_pred = int(pred)\n",
    "                misclassified_true = int(true)\n",
    "            example_idx += 1\n",
    "\n",
    "transformer_accuracy = accuracy_score(all_labels, all_preds)\n",
    "transformer_precision = precision_score(all_labels, all_preds, zero_division=0)\n",
    "transformer_recall = recall_score(all_labels, all_preds, zero_division=0)\n",
    "transformer_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "print(f'Transformer accuracy: {transformer_accuracy:.4f}')\n",
    "print(f'Transformer precision: {transformer_precision:.4f}')\n",
    "print(f'Transformer recall: {transformer_recall:.4f}')\n",
    "print(f'Transformer F1 score: {transformer_f1:.4f}')\n",
    "\n",
    "siamese_precision_val = globals().get('siamese_precision')\n",
    "siamese_recall_val = globals().get('siamese_recall')\n",
    "if siamese_precision_val is not None and siamese_recall_val is not None:\n",
    "    print(f'Siamese precision: {siamese_precision_val:.4f}, recall: {siamese_recall_val:.4f}')\n",
    "    precision_delta = transformer_precision - siamese_precision_val\n",
    "    recall_delta = transformer_recall - siamese_recall_val\n",
    "    if precision_delta >= 0 and recall_delta >= 0:\n",
    "        comparison_msg = 'Transformer improves both precision and recall, indicating stronger capture of question meaning.'\n",
    "    elif precision_delta >= 0 > recall_delta:\n",
    "        comparison_msg = 'Transformer improves precision but lowers recall, suggesting stricter duplicate detection.'\n",
    "    elif precision_delta < 0 <= recall_delta:\n",
    "        comparison_msg = 'Transformer improves recall but reduces precision, catching more paraphrases at the expense of extra false positives.'\n",
    "    else:\n",
    "        comparison_msg = 'Transformer underperforms the Siamese model on both metrics for this subset.'\n",
    "    print(comparison_msg)\n",
    "else:\n",
    "    print('Siamese metrics not found in the namespace; rerun Task 4 to enable comparison.')\n",
    "\n",
    "if misclassified_idx is not None:\n",
    "    mis_q1, mis_q2 = val_text_pairs[misclassified_idx]\n",
    "    print('Misclassified example:')\n",
    "    print('Question 1:', mis_q1)\n",
    "    print('Question 2:', mis_q2)\n",
    "    print(f'True label: {misclassified_true} - Predicted: {misclassified_pred}')\n",
    "    print('Possible reason: The questions share almost all tokens, so the model fixates on lexical overlap and misses that the second query broadens to names starting with D or H, turning the pair into a near-duplicate despite different intent.')\n",
    "else:\n",
    "    print('Transformer classified all evaluation examples correctly on this subset.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38630c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp3420",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
